{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use CNN Network to process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import Input, Dense, Flatten, Reshape, BatchNormalization\n",
    "from keras.layers import Conv1D, UpSampling1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import ReLU\n",
    "from keras.optimizers import RMSprop\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "csv_file = '/Users/robert/src/MachineLearning/processed_result/merged_data.csv'\n",
    "sname = [\"ted\", \"Lei\", \"Lema\", \"Erin\", \"Claire\", \"jaden\", \"wenxin\"]\n",
    "lblList = ['Relaxation', 'CPT Test', 'Stroop Test', 'Math Test', 'Video 1', 'Video 2']\n",
    "feat = [\"EDA\"]\n",
    "sc = 'Shimmer_FCF4_GSR_Skin_Conductance_CAL'\n",
    "eda = 'Normalized_GSR'\n",
    "lbl = 'Event_Label'\n",
    "\n",
    "sf_EDA = 4\n",
    "window = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'EDA', 'Label'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(csv_file)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_model:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "\n",
    "        self.batch_size = int(sf_EDA*window) \n",
    "\n",
    "        self.sname = self.df[\"Name\"].unique()\n",
    "        self.K = len(self.df[\"Label\"].unique())\n",
    "        \n",
    "    def one_hot_enc(self, r, k):\n",
    "        new_r = np.zeros((r.shape[0],k))\n",
    "        for i, val in enumerate(r):\n",
    "            new_r[i, val-1] = 1\n",
    "\n",
    "        return new_r\n",
    "    \n",
    "    def get_data(self, test_id, v_batch_size, v_feat_list, df):\n",
    "        \n",
    "        cnt=0\n",
    "        \n",
    "        for name in self.sname:\n",
    "            df_s = df[df[\"Name\"] == name]\n",
    "\n",
    "            n = (len(df_s)//v_batch_size)*v_batch_size\n",
    "            df_s = df_s[:n]\n",
    "            s = StandardScaler().fit_transform(df_s[v_feat_list])\n",
    "            s = s.reshape(int(s.shape[0]/v_batch_size), s.shape[1],  v_batch_size)\n",
    "\n",
    "            lbl_m = np.zeros((s.shape[0],1))\n",
    "            lbl = df_s[\"Label\"].values.astype(int)\n",
    "            for i in range(s.shape[0]):\n",
    "                lbl_m[i] = int((stats.mode(lbl[i * v_batch_size : (i + 1) * v_batch_size - 1]))[0].squeeze())\n",
    "            y_k = lbl_m.astype(int)\n",
    "            s_y = self.one_hot_enc(lbl_m.astype(int), self.K).astype(int)\n",
    "            if name==test_id:\n",
    "                x_test = s\n",
    "                y_test = s_y\n",
    "                yk_test = y_k\n",
    "            else:\n",
    "                if cnt:\n",
    "                    x_train = np.concatenate((x_train, s), axis=0)\n",
    "                    y_train = np.concatenate((y_train, s_y), axis=0)\n",
    "                    yk_train = np.concatenate((yk_train, y_k), axis=0)\n",
    "                else:\n",
    "                    x_train = s\n",
    "                    y_train = s_y\n",
    "                    yk_train = y_k\n",
    "                cnt +=1\n",
    "\n",
    "\n",
    "        print (\"merged train:\", x_train.shape, y_train.shape)\n",
    "        print (\"merged test :\", x_test.shape, y_test.shape)\n",
    "        return x_train, y_train, x_test, y_test, yk_train, yk_test\n",
    "\n",
    "    def cnn_model(self, v_batch_size, n_feat):\n",
    "        \n",
    "        input_sig = Input(shape=(n_feat, v_batch_size))\n",
    "        x = Conv1D(v_batch_size,4, activation='relu', padding='same')(input_sig)\n",
    "\n",
    "        x1 = BatchNormalization()(x)\n",
    "        flat = Flatten()(x1)\n",
    "        encoded = Dense(4, activation='relu')(flat)\n",
    "        cls = Dense(5, activation='softmax')(encoded)\n",
    "\n",
    "        model= Model(input_sig, cls)\n",
    "\n",
    "        return model \n",
    "    \n",
    "    def test_model (self, v_df):\n",
    "        scores = []\n",
    "        for name in self.sname:\n",
    "            print(\"============= test subject \" +name+ \" ==================\")\n",
    "            x_train, y_train, x_test, y_test, yk, yk_test = self.get_data (test_id = name,\n",
    "                                                                           v_batch_size=sf_EDA,\n",
    "                                                                           v_feat_list=feat, \n",
    "                                                                           df=self.df)\n",
    "            model = self.cnn_model(v_batch_size=sf_EDA, n_feat=len(feat))\n",
    "            model.compile(optimizer=RMSprop(learning_rate=0.00025), loss=\"categorical_crossentropy\")\n",
    "            history = model.fit(x_train, y_train, epochs=4)\n",
    "\n",
    "            pred_train = model.predict(x_train)\n",
    "            pred_test = model.predict(x_test)\n",
    "            acc = accuracy_score(np.argmax(y_test, axis=1), np.argmax(pred_test, axis=1))\n",
    "            f1 = f1_score(np.argmax(y_test, axis=1), np.argmax(pred_test, axis=1), average='weighted')\n",
    "\n",
    "            scores.append([name, acc, f1])\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= test subject ted ==================\n"
     ]
    }
   ],
   "source": [
    "cnn_m = cnn_model()\n",
    "scores = cnn_m.test_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
